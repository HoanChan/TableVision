{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXO2lMCahsiE",
        "outputId": "3a1d16de-f10d-42b4-e0a9-f0090a82c281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TableVision'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 165 (delta 29), reused 69 (delta 15), pack-reused 81\u001b[K\n",
            "Receiving objects: 100% (165/165), 214.12 MiB | 16.26 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Updating files: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HoanChan/TableVision.git TableVision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TableVision && git reset --hard"
      ],
      "metadata": {
        "id": "OM8dAxcXgxdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd TableVision && git pull"
      ],
      "metadata": {
        "id": "kfUf3DPHgznd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYWIxLq4iRVu",
        "outputId": "607fc2e0-422e-4730-a2e8-e8d6f80bf450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.6-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.6 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.6 PyMuPDFb-1.23.6\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JTkMiMPjB2r",
        "outputId": "601edc4d-a651-46aa-e2ba-03e9b2d79b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Datasets/TNCR'...\n",
            "remote: Enumerating objects: 13228, done.\u001b[K\n",
            "remote: Total 13228 (delta 0), reused 0 (delta 0), pack-reused 13228\u001b[K\n",
            "Receiving objects: 100% (13228/13228), 1.55 GiB | 15.61 MiB/s, done.\n",
            "Resolving deltas: 100% (6170/6170), done.\n",
            "Updating files: 100% (13246/13246), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HoanChan/TNCR_DETR Datasets/TNCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnEpEGYHjbtQ"
      },
      "outputs": [],
      "source": [
        "# TNCR_labels = ['full_lined', 'partial_lined_merged_cells', 'nolines', 'partial_lined', 'merged_cells']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir  /content/Datasets/TNCR/val"
      ],
      "metadata": {
        "id": "FdNbmJnzg3Vb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZI5a-QhO7NfS"
      },
      "outputs": [],
      "source": [
        "def split_pth_file(input_file, output_file1, output_file2):\n",
        "    with open(input_file, 'rb') as f:\n",
        "        data = f.read()\n",
        "\n",
        "    half_len = len(data) // 2\n",
        "\n",
        "    with open(output_file1, 'wb') as f1, open(output_file2, 'wb') as f2:\n",
        "        f1.write(data[:half_len])\n",
        "        f2.write(data[half_len:])\n",
        "\n",
        "def combine_pth_files(input_file1, input_file2, output_file):\n",
        "    with open(input_file1, 'rb') as f1, open(input_file2, 'rb') as f2:\n",
        "        data1 = f1.read()\n",
        "        data2 = f2.read()\n",
        "\n",
        "    combined_data = data1 + data2\n",
        "\n",
        "    with open(output_file, 'wb') as f:\n",
        "        f.write(combined_data)\n",
        "\n",
        "combine_pth_files(\"/content/TableVision/models/pubtables1m_detection_detr_r18.pth_part1\", \"/content/TableVision/models/pubtables1m_detection_detr_r18.pth_part2\", \"/content/TableVision/models/pubtables1m_detection_detr_r18.pth\")\n",
        "combine_pth_files(\"/content/TableVision/models/pubtables1m_structure_detr_r18.pth_part1\", \"/content/TableVision/models/pubtables1m_structure_detr_r18.pth_part2\", \"/content/TableVision/models/pubtables1m_structure_detr_r18.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrckPio4_qvs",
        "outputId": "44d9069a-4218-4b75-c3ba-55b67feb9317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before clearing sys.path:\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(\"Before clearing sys.path:\")\n",
        "print(sys.path)\n",
        "# print(sys.path.index('/root/.ipython'))\n",
        "sys.path=sys.path[:10]\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path=sys.path[:10]\n",
        "sys.path.append('/content/TableVision/src')\n",
        "from main import main\n",
        "import json\n",
        "\n",
        "# Đọc nội dung tệp JSON vào biến args\n",
        "with open('/content/TableVision/TNCR_train_args.json', 'r') as f:\n",
        "    args = dict(json.load(f))\n",
        "main(args)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut_SACyLhBQ8",
        "outputId": "8d718abb-847c-4c34-86b9-9f99f1a60859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data_root_dir': '/content/Datasets/TNCR', 'config_file': 'config.yaml', 'backbone': 'resnet18', 'data_type': 'detection', 'model_load_path': None, 'load_weights_only': True, 'model_save_dir': '/content/models', 'metrics_save_filepath': '/content/metrics', 'debug_save_dir': 'debug', 'table_words_dir': '/content/table_words', 'mode': 'train', 'debug': False, 'device': 'cuda', 'lr': 5e-05, 'lr_drop': 1, 'lr_gamma': 0.9, 'epochs': 20, 'checkpoint_freq': 1, 'batch_size': 2, 'num_workers': 1, 'train_max_size': 1024, 'val_max_size': 512, 'test_max_size': 512, 'eval_pool_size': 1, 'eval_step': 1, 'lr_backbone': 1e-05, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'num_classes': 5, 'dilation': False, 'position_embedding': 'sine', 'emphasized_weights': {}, 'enc_layers': 6, 'dec_layers': 6, 'dim_feedforward': 2048, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 110, 'pre_norm': True, 'masks': False, 'aux_loss': False, 'mask_loss_coef': 1, 'dice_loss_coef': 1, 'ce_loss_coef': 1, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, 'eos_coef': 0.4, 'set_cost_class': 1, 'set_cost_bbox': 5, 'set_cost_giou': 2, 'seed': 42, 'start_epoch': 0, '__module__': 'main', '__dict__': <attribute '__dict__' of 'Args' objects>, '__weakref__': <attribute '__weakref__' of 'Args' objects>, '__doc__': None}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "loading model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 71.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "loading data\n",
            "creating index...\n",
            "index created!\n",
            "finished loading data in : 0:00:00.023204\n",
            "Max batches per epoch: 512\n",
            "Output directory:  /content/models\n",
            "Output model path:  /content/models/model.pth\n",
            "Start training\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [0]  [  0/512]  eta: 0:24:08  lr: 0.000050  class_error: 50.00  loss: 8.5600 (8.5600)  loss_ce: 2.4195 (2.4195)  loss_bbox: 4.1207 (4.1207)  loss_giou: 2.0198 (2.0198)  loss_ce_unscaled: 2.4195 (2.4195)  class_error_unscaled: 50.0000 (50.0000)  loss_bbox_unscaled: 0.8241 (0.8241)  loss_giou_unscaled: 1.0099 (1.0099)  cardinality_error_unscaled: 109.0000 (109.0000)  time: 2.8296  data: 0.2092  max mem: 647\n",
            "Epoch: [0]  [511/512]  eta: 0:00:00  lr: 0.000050  class_error: 100.00  loss: 1.9350 (3.2307)  loss_ce: 0.1639 (0.1970)  loss_bbox: 1.0092 (1.9066)  loss_giou: 0.8065 (1.1271)  loss_ce_unscaled: 0.1639 (0.1970)  class_error_unscaled: 100.0000 (99.9023)  loss_bbox_unscaled: 0.2018 (0.3813)  loss_giou_unscaled: 0.4033 (0.5635)  cardinality_error_unscaled: 1.0000 (1.5898)  time: 0.2116  data: 0.0195  max mem: 1527\n",
            "Epoch: [0] Total time: 0:01:39 (0.1941 s / it)\n",
            "Averaged stats: lr: 0.000050  class_error: 100.00  loss: 1.9350 (3.2307)  loss_ce: 0.1639 (0.1970)  loss_bbox: 1.0092 (1.9066)  loss_giou: 0.8065 (1.1271)  loss_ce_unscaled: 0.1639 (0.1970)  class_error_unscaled: 100.0000 (99.9023)  loss_bbox_unscaled: 0.2018 (0.3813)  loss_giou_unscaled: 0.4033 (0.5635)  cardinality_error_unscaled: 1.0000 (1.5898)\n",
            "Epoch completed in  0:01:39.400131\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [1]  [  0/512]  eta: 0:03:24  lr: 0.000045  class_error: 100.00  loss: 2.0610 (2.0610)  loss_ce: 0.1750 (0.1750)  loss_bbox: 1.0820 (1.0820)  loss_giou: 0.8041 (0.8041)  loss_ce_unscaled: 0.1750 (0.1750)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2164 (0.2164)  loss_giou_unscaled: 0.4021 (0.4021)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.3992  data: 0.2196  max mem: 1527\n",
            "Epoch: [1]  [511/512]  eta: 0:00:00  lr: 0.000045  class_error: 100.00  loss: 1.6736 (1.9099)  loss_ce: 0.1422 (0.1866)  loss_bbox: 0.6632 (1.0041)  loss_giou: 0.6604 (0.7192)  loss_ce_unscaled: 0.1422 (0.1866)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1326 (0.2008)  loss_giou_unscaled: 0.3302 (0.3596)  cardinality_error_unscaled: 1.0000 (1.3828)  time: 0.2424  data: 0.0164  max mem: 1527\n",
            "Epoch: [1] Total time: 0:01:40 (0.1961 s / it)\n",
            "Averaged stats: lr: 0.000045  class_error: 100.00  loss: 1.6736 (1.9099)  loss_ce: 0.1422 (0.1866)  loss_bbox: 0.6632 (1.0041)  loss_giou: 0.6604 (0.7192)  loss_ce_unscaled: 0.1422 (0.1866)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1326 (0.2008)  loss_giou_unscaled: 0.3302 (0.3596)  cardinality_error_unscaled: 1.0000 (1.3828)\n",
            "Epoch completed in  0:01:40.408592\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [2]  [  0/512]  eta: 0:03:49  lr: 0.000041  class_error: 100.00  loss: 2.0916 (2.0916)  loss_ce: 0.2142 (0.2142)  loss_bbox: 0.7738 (0.7738)  loss_giou: 1.1036 (1.1036)  loss_ce_unscaled: 0.2142 (0.2142)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1548 (0.1548)  loss_giou_unscaled: 0.5518 (0.5518)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.4492  data: 0.2150  max mem: 1527\n",
            "Epoch: [2]  [511/512]  eta: 0:00:00  lr: 0.000041  class_error: 100.00  loss: 1.4000 (1.6602)  loss_ce: 0.1776 (0.1871)  loss_bbox: 0.5965 (0.8363)  loss_giou: 0.4697 (0.6368)  loss_ce_unscaled: 0.1776 (0.1871)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1193 (0.1673)  loss_giou_unscaled: 0.2348 (0.3184)  cardinality_error_unscaled: 1.5000 (1.3809)  time: 0.2392  data: 0.0143  max mem: 1527\n",
            "Epoch: [2] Total time: 0:01:50 (0.2160 s / it)\n",
            "Averaged stats: lr: 0.000041  class_error: 100.00  loss: 1.4000 (1.6602)  loss_ce: 0.1776 (0.1871)  loss_bbox: 0.5965 (0.8363)  loss_giou: 0.4697 (0.6368)  loss_ce_unscaled: 0.1776 (0.1871)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1193 (0.1673)  loss_giou_unscaled: 0.2348 (0.3184)  cardinality_error_unscaled: 1.5000 (1.3809)\n",
            "Epoch completed in  0:01:50.576021\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [3]  [  0/512]  eta: 0:04:00  lr: 0.000036  class_error: 100.00  loss: 1.0245 (1.0245)  loss_ce: 0.1304 (0.1304)  loss_bbox: 0.5313 (0.5313)  loss_giou: 0.3629 (0.3629)  loss_ce_unscaled: 0.1304 (0.1304)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1063 (0.1063)  loss_giou_unscaled: 0.1814 (0.1814)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.4698  data: 0.2342  max mem: 1527\n",
            "Epoch: [3]  [511/512]  eta: 0:00:00  lr: 0.000036  class_error: 100.00  loss: 1.5493 (1.5414)  loss_ce: 0.1545 (0.1843)  loss_bbox: 0.7469 (0.7723)  loss_giou: 0.5150 (0.5848)  loss_ce_unscaled: 0.1545 (0.1843)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1494 (0.1545)  loss_giou_unscaled: 0.2575 (0.2924)  cardinality_error_unscaled: 1.0000 (1.3789)  time: 0.2552  data: 0.0159  max mem: 1528\n",
            "Epoch: [3] Total time: 0:01:52 (0.2207 s / it)\n",
            "Averaged stats: lr: 0.000036  class_error: 100.00  loss: 1.5493 (1.5414)  loss_ce: 0.1545 (0.1843)  loss_bbox: 0.7469 (0.7723)  loss_giou: 0.5150 (0.5848)  loss_ce_unscaled: 0.1545 (0.1843)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1494 (0.1545)  loss_giou_unscaled: 0.2575 (0.2924)  cardinality_error_unscaled: 1.0000 (1.3789)\n",
            "Epoch completed in  0:01:52.982712\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [4]  [  0/512]  eta: 0:04:19  lr: 0.000033  class_error: 100.00  loss: 2.4829 (2.4829)  loss_ce: 0.2367 (0.2367)  loss_bbox: 1.4581 (1.4581)  loss_giou: 0.7881 (0.7881)  loss_ce_unscaled: 0.2367 (0.2367)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2916 (0.2916)  loss_giou_unscaled: 0.3940 (0.3940)  cardinality_error_unscaled: 2.0000 (2.0000)  time: 0.5069  data: 0.2416  max mem: 1528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python /content/TableVision/src/main.py --data_root_dir=\"/content/Datasets/TNCR\" --config_file=\"/content/TableVision/TNCR_train_args.json\""
      ],
      "metadata": {
        "id": "MPYpM1JdiknK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIdrFGo060w_",
        "outputId": "98e84f4c-2f35-4766-a777-34159d28fc17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection model initialized.\n",
            "Detection model weights loaded.\n",
            "Structure model initialized.\n",
            "Structure model weights loaded.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "# Thêm đường dẫn đến thư mục 'src' vào danh sách đường dẫn\n",
        "sys.path=sys.path[:10]\n",
        "\n",
        "# sys.path.append('/content/TableVision/')\n",
        "sys.path.append('/content/Pubtable-1M/')\n",
        "sys.path.append('/content/Pubtable-1M/src/')\n",
        "sys.path.append('/content/Pubtable-1M/detr/')\n",
        "\n",
        "from src.inference import TableExtractionPipeline\n",
        "\n",
        "# Create inference pipeline\n",
        "pipe = TableExtractionPipeline(det_config_path='/content/manual_args.json',\n",
        "                               det_model_path='/content/models/model_20.pth', det_device='cuda',\n",
        "                               str_config_path='/content/Pubtable-1M/src/structure_config.json',\n",
        "                               str_model_path='/content/TableVision/models/pubtables1m_structure_detr_r18.pth', str_device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWgcC1kg4n6x"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "class_map_color = {\n",
        "          'full_lined': (1, 0, 0.6),\n",
        "          'partial_lined_merged_cells': (0.6, 1, 0.6),\n",
        "          'nolines': (0.6, 0.6, 1),\n",
        "          'partial_lined': (1, 0.6, 1),\n",
        "          'merged_cells': (0.6, 1, 1),\n",
        "          'no object':  (0.6, 0.6, 0.6)\n",
        "      }\n",
        "\n",
        "def visualize_detected_tables(img, det_tables, out_path):\n",
        "    plt.imshow(img, interpolation=\"lanczos\")\n",
        "    plt.gcf().set_size_inches(20, 20)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for det_table in det_tables:\n",
        "      label = det_table['label']\n",
        "      if label not in class_map_color: continue\n",
        "      bbox = det_table['bbox']\n",
        "      facecolor = edgecolor = class_map_color[label]\n",
        "      alpha = 0.3\n",
        "      linewidth = 2\n",
        "      hatch='//////'\n",
        "\n",
        "      rect = patches.Rectangle(bbox[:2], bbox[2]-bbox[0], bbox[3]-bbox[1], linewidth=linewidth, edgecolor='none',facecolor=facecolor, alpha=0.1)\n",
        "      ax.add_patch(rect)\n",
        "      rect = patches.Rectangle(bbox[:2], bbox[2]-bbox[0], bbox[3]-bbox[1], linewidth=linewidth, edgecolor=edgecolor,facecolor='none',linestyle='-', alpha=alpha)\n",
        "      ax.add_patch(rect)\n",
        "      rect = patches.Rectangle(bbox[:2], bbox[2]-bbox[0], bbox[3]-bbox[1], linewidth=0, edgecolor=edgecolor,facecolor='none',linestyle='-', hatch=hatch, alpha=0.2)\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "    plt.xticks([], [])\n",
        "    plt.yticks([], [])\n",
        "\n",
        "    legend_elements = []\n",
        "    for label, color in class_map_color.items():\n",
        "      legend_elements+=[Patch(facecolor=color, edgecolor=color, label=label, hatch='//////', alpha=0.3)]\n",
        "\n",
        "    plt.legend(handles=legend_elements, bbox_to_anchor=(0.5, -0.02), loc='upper center', borderaxespad=0, fontsize=10, ncol=2)\n",
        "    plt.gcf().set_size_inches(10, 10)\n",
        "    plt.axis('off')\n",
        "    plt.savefig(out_path, bbox_inches='tight', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta1EEjLZ8tid"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "# from src.inference import visualize_detected_tables\n",
        "from src.inference import visualize_cells\n",
        "\n",
        "def deleteFile(file_path):\n",
        "  try:\n",
        "      # Thực hiện xoá file\n",
        "      import os\n",
        "      os.remove(file_path)\n",
        "      print(f\"{file_path} đã được xoá thành công.\")\n",
        "  except FileNotFoundError:\n",
        "      print(f\"File {file_path} không tồn tại.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Lỗi khi xoá file {file_path}: {e}\")\n",
        "\n",
        "def crop(img, bbox, margin = 10, padding = 20):\n",
        "  # Tạo ảnh mới có kích thước lớn hơn để chứa ảnh cũ và padding\n",
        "  crop_img = img.crop((bbox[0] - margin, bbox[1] - margin, bbox[2] + margin, bbox[3] + margin))\n",
        "  new_width = crop_img.width + 2 * padding\n",
        "  new_height = crop_img.height + 2 * padding\n",
        "  # Tạo ảnh mới với kích thước lớn hơn\n",
        "  new_img = Image.new(\"RGB\", (new_width, new_height), (255, 255, 255))  # Màu nền trắng, bạn có thể thay đổi nếu muốn\n",
        "  # Đặt ảnh cũ vào vị trí giữa ảnh mới\n",
        "  new_img.paste(crop_img, (padding, padding))\n",
        "  return new_img\n",
        "\n",
        "def detectTable(pipe, img_path):\n",
        "  img = Image.open(img_path)\n",
        "  tokens = {}\n",
        "  extracted_tables = pipe.detect(img)\n",
        "  print(extracted_tables)\n",
        "  visualize_detected_tables(img, extracted_tables['objects'], \"/content/0.jpg\")\n",
        "  img_tables = Image.open(\"/content/0.jpg\")\n",
        "  img_data = [(img, img_tables)]\n",
        "  for index, objects in enumerate(extracted_tables['objects']):\n",
        "    bbox = objects['bbox']\n",
        "    cropped_img = crop(img, bbox, 10, 20)\n",
        "    extracted_cell = pipe.recognize(cropped_img, tokens, out_objects=True, out_cells=True, out_html=True, out_csv=True)\n",
        "    cells = extracted_cell['cells']\n",
        "    csv = extracted_cell['csv']\n",
        "    html = extracted_cell['html']\n",
        "    visualize_cells(cropped_img, cells[0], \"/content/2.jpg\")\n",
        "    img_cell = Image.open('/content/2.jpg')\n",
        "    img_data += [(cropped_img, img_cell)]\n",
        "\n",
        "  num_img = 1 + len(img_data)\n",
        "\n",
        "  plt.figure(figsize=(10, 5*num_img))\n",
        "  plot_size = num_img * 100 + 20\n",
        "  for index, imgs in enumerate(img_data):\n",
        "    img1, img2 = imgs\n",
        "    plt.subplot(plot_size + index * 2 + 1)\n",
        "    plt.imshow(img1)\n",
        "    plt.title('Image 1')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(plot_size + index * 2 + 2)\n",
        "    plt.imshow(img2)\n",
        "    plt.title('Image 2')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.show()\n",
        "  deleteFile(\"/content/0.jpg\")\n",
        "  deleteFile(\"/content/1.jpg\")\n",
        "  deleteFile(\"/content/2.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "lIJGdIGL8vMQ",
        "outputId": "14054f52-a91d-4b83-ef14-cd0835b0062c"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fe212cce6932>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetectTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/TableVision/sample/vn0.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-3047451814e1>\u001b[0m in \u001b[0;36mdetectTable\u001b[0;34m(pipe, img_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m   \u001b[0mextracted_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_tables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mvisualize_detected_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'objects'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/0.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pubtable-1M/src/inference.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, tokens, out_objects, out_crops, crop_padding)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mout_formats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No detection model loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout_formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Pubtable-1M/src/inference.py\u001b[0m in \u001b[0;36moutputs_to_objects\u001b[0;34m(outputs, img_size, class_idx2name)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable_structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moutputs_to_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx2name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 5"
          ]
        }
      ],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn0.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghtAZ3xnE9OV"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn1.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAnmyNVzFA-J"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn2.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyxoxVZ1FEhs"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn3.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-res2YWiFJrj"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn4.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22R6FQBGFRU5"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn5.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKzAfQXxFW-o"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn6.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-Zwc0MpFc9A"
      },
      "outputs": [],
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/tablex2.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpK67AAfFlCX"
      },
      "outputs": [],
      "source": [
        "def convert_png_to_jpeg(png_path, jpeg_path):\n",
        "    # Đọc ảnh từ file PNG\n",
        "    image = Image.open(png_path)\n",
        "    # Chuyển đổi và lưu ảnh dưới định dạng JPEG\n",
        "    image.convert(\"RGB\").save(jpeg_path, \"JPEG\")\n",
        "\n",
        "convert_png_to_jpeg(\"/content/TableVision/sample/tablex3.png\",\"/content/TableVision/sample/tablex3.jpg\")\n",
        "detectTable(pipe, \"/content/TableVision/sample/tablex3.jpg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}