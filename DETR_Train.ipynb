{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXO2lMCahsiE",
        "outputId": "90188450-21ff-4d12-e9af-70f14072442e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'table-transformer'...\n",
            "remote: Enumerating objects: 753, done.\u001b[K\n",
            "remote: Counting objects: 100% (436/436), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 753 (delta 339), reused 386 (delta 306), pack-reused 317\u001b[K\n",
            "Receiving objects: 100% (753/753), 351.31 KiB | 1.44 MiB/s, done.\n",
            "Resolving deltas: 100% (466/466), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/microsoft/table-transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYWIxLq4iRVu",
        "outputId": "7f044c4a-bc3f-4496-fffa-05e17eee8f82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.6-cp310-none-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.6 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.6 PyMuPDFb-1.23.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HoanChan/TNCR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JTkMiMPjB2r",
        "outputId": "4f9fd0a8-086f-4743-980c-c9a228e8be9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TNCR'...\n",
            "remote: Enumerating objects: 13229, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 13229 (delta 1), reused 3 (delta 0), pack-reused 13223\u001b[K\n",
            "Receiving objects: 100% (13229/13229), 1.79 GiB | 30.59 MiB/s, done.\n",
            "Resolving deltas: 100% (6240/6240), done.\n",
            "Updating files: 100% (13243/13243), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xử lý lại file của TNCR cho đúng định dạng của Pubtables-1M\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Bước 1: Lập danh sách các file xml trong thư mục TNCR\n",
        "data_dir = 'TNCR/TNCR'\n",
        "xml_files = [file for file in os.listdir(data_dir) if file.endswith('.xml')]\n",
        "\n",
        "# Bước 2: Chia các file thành 2 tập train và test\n",
        "train_files, test_files = train_test_split(xml_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bước 3: Di chuyển các file tương ứng vào 2 thư mục train và test\n",
        "train_dir = 'TNCR/train'\n",
        "test_dir = 'TNCR/test'\n",
        "image_dir = 'TNCR/images'\n",
        "val_dir = 'TNCR/val'\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "for file_name in train_files:\n",
        "    source_path = os.path.join(data_dir, file_name)\n",
        "    destination_path = os.path.join(train_dir, file_name)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "for file_name in test_files:\n",
        "    source_path = os.path.join(data_dir, file_name)\n",
        "    destination_path = os.path.join(test_dir, file_name)\n",
        "    shutil.move(source_path, destination_path)\n",
        "\n",
        "# Bước 4: Tạo 2 file chứa danh sách file train và file test\n",
        "with open('TNCR/train_filelist.txt', 'w') as train_filelist:\n",
        "    train_filelist.write('train/'+'\\ntrain/'.join(train_files))\n",
        "\n",
        "with open('TNCR/test_filelist.txt', 'w') as test_filelist:\n",
        "    test_filelist.write('test/'+'\\ntest/'.join(test_files))\n",
        "\n",
        "# Bước 5: Đổi tên thư mục TNCR thành image\n",
        "os.rename(data_dir, image_dir)\n",
        "\n",
        "img_files = [file for file in os.listdir(image_dir) if file.endswith('.png')]\n",
        "with open('TNCR/images_filelist.txt', 'w') as images_filelist:\n",
        "    images_filelist.write('images/'+'\\nimages/'.join(img_files))\n"
      ],
      "metadata": {
        "id": "OAHggARLxDfQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TNCR_labels = ['full_lined', 'partial_lined_merged_cells', 'nolines', 'partial_lined', 'merged_cells']"
      ],
      "metadata": {
        "id": "WnEpEGYHjbtQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import các thư viện cần thiết\n",
        "import os\n",
        "import argparse\n",
        "import json\n",
        "from datetime import datetime\n",
        "import string\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "sys.path.append(\"/content/table-transformer/detr\")\n",
        "from engine import evaluate, train_one_epoch\n",
        "from models import build_model\n",
        "import util.misc as utils\n",
        "import datasets.transforms as R\n",
        "\n",
        "\n",
        "sys.path.append(\"/content/table-transformer/src\")\n",
        "import table_datasets as TD\n",
        "from table_datasets import PDFTablesDataset\n",
        "from eval import eval_coco"
      ],
      "metadata": {
        "id": "pGDscSBHicpe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(data_type, image_set):\n",
        "    if data_type == 'structure':\n",
        "        return TD.get_structure_transform(image_set)\n",
        "    else:\n",
        "        return TD.get_detection_transform(image_set)\n",
        "\n",
        "def get_class_map(data_type):\n",
        "    if data_type == 'structure':\n",
        "        class_map = {\n",
        "            'table': 0,\n",
        "            'table column': 1,\n",
        "            'table row': 2,\n",
        "            'table column header': 3,\n",
        "            'table projected row header': 4,\n",
        "            'table spanning cell': 5,\n",
        "            'no object': 6\n",
        "        }\n",
        "    else:\n",
        "        # class_map = {'table': 0, 'table rotated': 1, 'no object': 2}\n",
        "        class_map = {\n",
        "            'full_lined': 0,\n",
        "            'partial_lined_merged_cells': 1,\n",
        "            'nolines': 2,\n",
        "            'partial_lined': 3,\n",
        "            'merged_cells': 4,\n",
        "            'no object':  5\n",
        "        }\n",
        "    return class_map"
      ],
      "metadata": {
        "id": "0pKAJiBsiwK1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(args):\n",
        "    \"\"\"\n",
        "    Based on the args, retrieves the necessary data to perform training,\n",
        "    evaluation or GriTS metric evaluation\n",
        "    \"\"\"\n",
        "    # Datasets\n",
        "    print(\"loading data\")\n",
        "    class_map = get_class_map(args.data_type)\n",
        "\n",
        "    if args.mode == \"train\":\n",
        "        dataset_train = PDFTablesDataset(\n",
        "            os.path.join(args.data_root_dir, \"train\"),\n",
        "            get_transform(args.data_type, \"train\"),\n",
        "            do_crop=False,\n",
        "            max_size=args.train_max_size,\n",
        "            include_eval=False,\n",
        "            max_neg=0,\n",
        "            make_coco=False,\n",
        "            image_extension=\".png\",\n",
        "            xml_fileset=\"train_filelist.txt\",\n",
        "            class_map=class_map)\n",
        "        dataset_val = PDFTablesDataset(os.path.join(args.data_root_dir, \"val\"),\n",
        "                                       get_transform(args.data_type, \"val\"),\n",
        "                                       do_crop=False,\n",
        "                                       max_size=args.val_max_size,\n",
        "                                       include_eval=False,\n",
        "                                       make_coco=True,\n",
        "                                       image_extension=\".jpg\",\n",
        "                                       xml_fileset=\"val_filelist.txt\",\n",
        "                                       class_map=class_map)\n",
        "\n",
        "        sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
        "        sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
        "\n",
        "        batch_sampler_train = torch.utils.data.BatchSampler(sampler_train,\n",
        "                                                            args.batch_size,\n",
        "                                                            drop_last=True)\n",
        "\n",
        "        data_loader_train = DataLoader(dataset_train,\n",
        "                                       batch_sampler=batch_sampler_train,\n",
        "                                       collate_fn=utils.collate_fn,\n",
        "                                       num_workers=args.num_workers)\n",
        "        data_loader_val = DataLoader(dataset_val,\n",
        "                                     2 * args.batch_size,\n",
        "                                     sampler=sampler_val,\n",
        "                                     drop_last=False,\n",
        "                                     collate_fn=utils.collate_fn,\n",
        "                                     num_workers=args.num_workers)\n",
        "        return data_loader_train, data_loader_val, dataset_val, len(\n",
        "            dataset_train)\n",
        "\n",
        "    elif args.mode == \"eval\":\n",
        "\n",
        "        dataset_test = PDFTablesDataset(os.path.join(args.data_root_dir,\n",
        "                                                     \"test\"),\n",
        "                                        get_transform(args.data_type, \"val\"),\n",
        "                                        do_crop=False,\n",
        "                                        max_size=args.test_max_size,\n",
        "                                        make_coco=True,\n",
        "                                        include_eval=True,\n",
        "                                        image_extension=\".png\",\n",
        "                                        xml_fileset=\"test_filelist.txt\",\n",
        "                                        class_map=class_map)\n",
        "        sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
        "\n",
        "        data_loader_test = DataLoader(dataset_test,\n",
        "                                      2 * args.batch_size,\n",
        "                                      sampler=sampler_test,\n",
        "                                      drop_last=False,\n",
        "                                      collate_fn=utils.collate_fn,\n",
        "                                      num_workers=args.num_workers)\n",
        "        return data_loader_test, dataset_test\n",
        "\n",
        "    elif args.mode == \"grits\" or args.mode == \"grits-all\":\n",
        "        dataset_test = PDFTablesDataset(os.path.join(args.data_root_dir,\n",
        "                                                     \"test\"),\n",
        "                                        RandomMaxResize(1000, 1000),\n",
        "                                        include_original=True,\n",
        "                                        max_size=args.max_test_size,\n",
        "                                        make_coco=False,\n",
        "                                        image_extension=\".png\",\n",
        "                                        xml_fileset=\"test_filelist.txt\",\n",
        "                                        class_map=class_map)\n",
        "        return dataset_test"
      ],
      "metadata": {
        "id": "a7fEcT3xizTX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(args, device):\n",
        "    \"\"\"\n",
        "    Loads DETR model on to the device specified.\n",
        "    If a load path is specified, the state dict is updated accordingly.\n",
        "    \"\"\"\n",
        "    model, criterion, postprocessors = build_model(args)\n",
        "    model.to(device)\n",
        "    if args.model_load_path:\n",
        "        print(\"loading model from checkpoint\")\n",
        "        loaded_state_dict = torch.load(args.model_load_path,\n",
        "                                       map_location=device)\n",
        "        model_state_dict = model.state_dict()\n",
        "        pretrained_dict = {\n",
        "            k: v\n",
        "            for k, v in loaded_state_dict.items()\n",
        "            if k in model_state_dict and model_state_dict[k].shape == v.shape\n",
        "        }\n",
        "        model_state_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_state_dict, strict=True)\n",
        "    return model, criterion, postprocessors\n"
      ],
      "metadata": {
        "id": "4qyYw6Q6i2Bg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, criterion, postprocessors, device):\n",
        "    \"\"\"\n",
        "    Training loop\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"loading data\")\n",
        "    dataloading_time = datetime.now()\n",
        "    data_loader_train, data_loader_val, dataset_val, train_len = get_data(args)\n",
        "    print(\"finished loading data in :\", datetime.now() - dataloading_time)\n",
        "\n",
        "    model_without_ddp = model\n",
        "    param_dicts = [\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in model_without_ddp.named_parameters()\n",
        "                if \"backbone\" not in n and p.requires_grad\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"params\": [\n",
        "                p for n, p in model_without_ddp.named_parameters()\n",
        "                if \"backbone\" in n and p.requires_grad\n",
        "            ],\n",
        "            \"lr\":\n",
        "            args.lr_backbone,\n",
        "        },\n",
        "    ]\n",
        "    optimizer = torch.optim.AdamW(param_dicts,\n",
        "                                  lr=args.lr,\n",
        "                                  weight_decay=args.weight_decay)\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                                   step_size=args.lr_drop,\n",
        "                                                   gamma=args.lr_gamma)\n",
        "\n",
        "    max_batches_per_epoch = int(train_len / args.batch_size)\n",
        "    print(\"Max batches per epoch: {}\".format(max_batches_per_epoch))\n",
        "\n",
        "    resume_checkpoint = False\n",
        "    if args.model_load_path:\n",
        "        checkpoint = torch.load(args.model_load_path, map_location='cpu')\n",
        "        if 'model_state_dict' in checkpoint:\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        if not args.load_weights_only and 'optimizer_state_dict' in checkpoint:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            resume_checkpoint = True\n",
        "        elif args.load_weights_only:\n",
        "            print(\"*** WARNING: Resuming training and ignoring optimzer state. \"\n",
        "                  \"Training will resume with new initialized values. \"\n",
        "                  \"To use current optimizer state, remove the --load_weights_only flag.\")\n",
        "        else:\n",
        "            print(\"*** ERROR: Optimizer state of saved checkpoint not found. \"\n",
        "                  \"To resume training with new initialized values add the --load_weights_only flag.\")\n",
        "            raise Exception(\"ERROR: Optimizer state of saved checkpoint not found. Must add --load_weights_only flag to resume training without.\")\n",
        "\n",
        "        if not args.load_weights_only and 'epoch' in checkpoint:\n",
        "            args.start_epoch = checkpoint['epoch'] + 1\n",
        "        elif args.load_weights_only:\n",
        "            print(\"*** WARNING: Resuming training and ignoring previously saved epoch. \"\n",
        "                  \"To resume from previously saved epoch, remove the --load_weights_only flag.\")\n",
        "        else:\n",
        "            print(\"*** WARNING: Epoch of saved model not found. Starting at epoch {}.\".format(args.start_epoch))\n",
        "\n",
        "    # Use user-specified save directory, if specified\n",
        "    if args.model_save_dir:\n",
        "        output_directory = args.model_save_dir\n",
        "    # If resuming from a checkpoint with optimizer state, save into same directory\n",
        "    elif args.model_load_path and resume_checkpoint:\n",
        "        output_directory = os.path.split(args.model_load_path)[0]\n",
        "    # Create new save directory\n",
        "    else:\n",
        "        run_date = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "        output_directory = os.path.join(args.data_root_dir, \"output\", run_date)\n",
        "\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "    print(\"Output directory: \", output_directory)\n",
        "    model_save_path = os.path.join(output_directory, 'model.pth')\n",
        "    print(\"Output model path: \", model_save_path)\n",
        "    if not resume_checkpoint and os.path.exists(model_save_path):\n",
        "        print(\"*** WARNING: Output model path exists but is not being used to resume training; training will overwrite it.\")\n",
        "\n",
        "    if args.start_epoch >= args.epochs:\n",
        "        print(\"*** WARNING: Starting epoch ({}) is greater or equal to the number of training epochs ({}).\".format(\n",
        "            args.start_epoch, args.epochs\n",
        "        ))\n",
        "\n",
        "    print(\"Start training\")\n",
        "    start_time = datetime.now()\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        print('-' * 100)\n",
        "\n",
        "        epoch_timing = datetime.now()\n",
        "        train_stats = train_one_epoch(\n",
        "            model,\n",
        "            criterion,\n",
        "            data_loader_train,\n",
        "            optimizer,\n",
        "            device,\n",
        "            epoch,\n",
        "            args.clip_max_norm,\n",
        "            max_batches_per_epoch=max_batches_per_epoch,\n",
        "            print_freq=1000)\n",
        "        print(\"Epoch completed in \", datetime.now() - epoch_timing)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # pubmed_stats, coco_evaluator = evaluate(model, criterion,\n",
        "        #                                         postprocessors,\n",
        "        #                                         data_loader_val, dataset_val,\n",
        "        #                                         device, None)\n",
        "        # print(\"pubmed: AP50: {:.3f}, AP75: {:.3f}, AP: {:.3f}, AR: {:.3f}\".\n",
        "        #       format(pubmed_stats['coco_eval_bbox'][1],\n",
        "        #              pubmed_stats['coco_eval_bbox'][2],\n",
        "        #              pubmed_stats['coco_eval_bbox'][0],\n",
        "        #              pubmed_stats['coco_eval_bbox'][8]))\n",
        "\n",
        "        # Save current model training progress\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    }, model_save_path)\n",
        "\n",
        "        # Save checkpoint for evaluation\n",
        "        if (epoch+1) % args.checkpoint_freq == 0:\n",
        "            model_save_path_epoch = os.path.join(output_directory, 'model_' + str(epoch+1) + '.pth')\n",
        "            torch.save(model.state_dict(), model_save_path_epoch)\n",
        "\n",
        "    print('Total training time: ', datetime.now() - start_time)"
      ],
      "metadata": {
        "id": "fwGnZZwRiddb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo các tham số.\n",
        "\n",
        "manual_args_dict = {\n",
        "    'data_root_dir': '/content/TNCR',\n",
        "    'config_file': 'config.yaml',\n",
        "    'backbone': 'resnet18',\n",
        "    'data_type': 'detection',\n",
        "    'model_load_path': None, # 'model_load_path': '/path/to/model.pth',\n",
        "    'load_weights_only': True,\n",
        "    'model_save_dir': '/content/models',\n",
        "    'metrics_save_filepath': '/content/metrics',\n",
        "    'debug_save_dir': 'debug',\n",
        "    'table_words_dir': '/content/table_words',\n",
        "    'mode': 'train',\n",
        "    'debug': False,\n",
        "    'device': 'cuda',\n",
        "    'lr': 0.001,\n",
        "    'lr_drop': 10,\n",
        "    'lr_gamma': 0.5,\n",
        "    'epochs': 50,\n",
        "    'checkpoint_freq': 1,\n",
        "    'batch_size': 32,\n",
        "    'num_workers': 4,\n",
        "    'train_max_size': 1024,\n",
        "    'val_max_size': 512,\n",
        "    'test_max_size': 512,\n",
        "    'eval_pool_size': 1,\n",
        "    'eval_step': 1,\n",
        "    \"lr\":5e-5,\n",
        "    \"lr_backbone\":1e-5,\n",
        "    \"batch_size\":2,\n",
        "    \"weight_decay\":1e-4,\n",
        "    \"epochs\":20,\n",
        "    \"lr_drop\":1,\n",
        "    \"lr_gamma\":0.9,\n",
        "    \"clip_max_norm\":0.1,\n",
        "    \"backbone\":\"resnet18\",\n",
        "    \"num_classes\":5,\n",
        "    \"dilation\":False,\n",
        "    \"position_embedding\":\"sine\",\n",
        "    \"emphasized_weights\":{},\n",
        "    \"enc_layers\":6,\n",
        "    \"dec_layers\":6,\n",
        "    \"dim_feedforward\":2048,\n",
        "    \"hidden_dim\":256,\n",
        "    \"dropout\":0.1,\n",
        "    \"nheads\":8,\n",
        "    \"num_queries\":110,\n",
        "    \"pre_norm\":True,\n",
        "    \"masks\":False,\n",
        "    \"aux_loss\":False,\n",
        "    \"mask_loss_coef\":1,\n",
        "    \"dice_loss_coef\":1,\n",
        "    \"ce_loss_coef\":1,\n",
        "    \"bbox_loss_coef\":5,\n",
        "    \"giou_loss_coef\":2,\n",
        "    \"eos_coef\":0.4,\n",
        "    \"set_cost_class\":1,\n",
        "    \"set_cost_bbox\":5,\n",
        "    \"set_cost_giou\":2,\n",
        "    \"device\":\"cuda\",\n",
        "    \"seed\":42,\n",
        "    \"start_epoch\":0,\n",
        "    \"num_workers\":1\n",
        "}"
      ],
      "metadata": {
        "id": "HuyZp_Mjif4A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_args = manual_args_dict\n",
        "args = type('Args', (object,), config_args)\n",
        "print(args.__dict__)\n",
        "print('-' * 100)\n",
        "\n",
        "# Check for debug mode\n",
        "if args.mode == 'eval' and args.debug:\n",
        "    print(\"Running evaluation/inference in DEBUG mode, processing will take longer. Saving output to: {}.\".format(args.debug_save_dir))\n",
        "    os.makedirs(args.debug_save_dir, exist_ok=True)\n",
        "\n",
        "# fix the seed for reproducibility\n",
        "seed = args.seed + utils.get_rank()\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "print(\"loading model\")\n",
        "device = torch.device(args.device)\n",
        "model, criterion, postprocessors = get_model(args, device)\n",
        "\n",
        "if args.mode == \"train\":\n",
        "    train(args, model, criterion, postprocessors, device)\n",
        "elif args.mode == \"eval\":\n",
        "    data_loader_test, dataset_test = get_data(args)\n",
        "    eval_coco(args, model, criterion, postprocessors, data_loader_test, dataset_test, device)"
      ],
      "metadata": {
        "id": "nZOlmtEKihSU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7b61916-52b0-4d42-f4ba-9ac7abf22830"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data_root_dir': '/content/TNCR', 'config_file': 'config.yaml', 'backbone': 'resnet18', 'data_type': 'detection', 'model_load_path': None, 'load_weights_only': True, 'model_save_dir': '/content/models', 'metrics_save_filepath': '/content/metrics', 'debug_save_dir': 'debug', 'table_words_dir': '/content/table_words', 'mode': 'train', 'debug': False, 'device': 'cuda', 'lr': 5e-05, 'lr_drop': 1, 'lr_gamma': 0.9, 'epochs': 20, 'checkpoint_freq': 1, 'batch_size': 2, 'num_workers': 1, 'train_max_size': 1024, 'val_max_size': 512, 'test_max_size': 512, 'eval_pool_size': 1, 'eval_step': 1, 'lr_backbone': 1e-05, 'weight_decay': 0.0001, 'clip_max_norm': 0.1, 'num_classes': 5, 'dilation': False, 'position_embedding': 'sine', 'emphasized_weights': {}, 'enc_layers': 6, 'dec_layers': 6, 'dim_feedforward': 2048, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 110, 'pre_norm': True, 'masks': False, 'aux_loss': False, 'mask_loss_coef': 1, 'dice_loss_coef': 1, 'ce_loss_coef': 1, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, 'eos_coef': 0.4, 'set_cost_class': 1, 'set_cost_bbox': 5, 'set_cost_giou': 2, 'seed': 42, 'start_epoch': 0, '__module__': '__main__', '__dict__': <attribute '__dict__' of 'Args' objects>, '__weakref__': <attribute '__weakref__' of 'Args' objects>, '__doc__': None}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "loading model\n",
            "loading data\n",
            "loading data\n",
            "creating index...\n",
            "index created!\n",
            "finished loading data in : 0:00:00.019577\n",
            "Max batches per epoch: 512\n",
            "Output directory:  /content/models\n",
            "Output model path:  /content/models/model.pth\n",
            "Start training\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [0]  [  0/512]  eta: 0:04:59  lr: 0.000050  class_error: 33.33  loss: 8.4681 (8.4681)  loss_ce: 2.4799 (2.4799)  loss_bbox: 3.9556 (3.9556)  loss_giou: 2.0326 (2.0326)  loss_ce_unscaled: 2.4799 (2.4799)  class_error_unscaled: 33.3333 (33.3333)  loss_bbox_unscaled: 0.7911 (0.7911)  loss_giou_unscaled: 1.0163 (1.0163)  cardinality_error_unscaled: 108.5000 (108.5000)  time: 0.5850  data: 0.1868  max mem: 1528\n",
            "Epoch: [0]  [511/512]  eta: 0:00:00  lr: 0.000050  class_error: 100.00  loss: 2.6635 (3.2177)  loss_ce: 0.1263 (0.1730)  loss_bbox: 1.4587 (1.8417)  loss_giou: 0.9614 (1.2031)  loss_ce_unscaled: 0.1263 (0.1730)  class_error_unscaled: 100.0000 (99.8698)  loss_bbox_unscaled: 0.2917 (0.3683)  loss_giou_unscaled: 0.4807 (0.6015)  cardinality_error_unscaled: 1.0000 (1.4834)  time: 0.2921  data: 0.0149  max mem: 1968\n",
            "Epoch: [0] Total time: 0:02:13 (0.2617 s / it)\n",
            "Averaged stats: lr: 0.000050  class_error: 100.00  loss: 2.6635 (3.2177)  loss_ce: 0.1263 (0.1730)  loss_bbox: 1.4587 (1.8417)  loss_giou: 0.9614 (1.2031)  loss_ce_unscaled: 0.1263 (0.1730)  class_error_unscaled: 100.0000 (99.8698)  loss_bbox_unscaled: 0.2917 (0.3683)  loss_giou_unscaled: 0.4807 (0.6015)  cardinality_error_unscaled: 1.0000 (1.4834)\n",
            "Epoch completed in  0:02:13.982270\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [1]  [  0/512]  eta: 0:04:57  lr: 0.000045  class_error: 100.00  loss: 2.5598 (2.5598)  loss_ce: 0.1236 (0.1236)  loss_bbox: 1.6255 (1.6255)  loss_giou: 0.8107 (0.8107)  loss_ce_unscaled: 0.1236 (0.1236)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.3251 (0.3251)  loss_giou_unscaled: 0.4053 (0.4053)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.5816  data: 0.2316  max mem: 1968\n",
            "Epoch: [1]  [511/512]  eta: 0:00:00  lr: 0.000045  class_error: 100.00  loss: 2.0705 (2.2465)  loss_ce: 0.1533 (0.1646)  loss_bbox: 1.0856 (1.2215)  loss_giou: 0.7770 (0.8604)  loss_ce_unscaled: 0.1533 (0.1646)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2171 (0.2443)  loss_giou_unscaled: 0.3885 (0.4302)  cardinality_error_unscaled: 1.0000 (1.2676)  time: 0.3161  data: 0.0130  max mem: 1968\n",
            "Epoch: [1] Total time: 0:02:21 (0.2757 s / it)\n",
            "Averaged stats: lr: 0.000045  class_error: 100.00  loss: 2.0705 (2.2465)  loss_ce: 0.1533 (0.1646)  loss_bbox: 1.0856 (1.2215)  loss_giou: 0.7770 (0.8604)  loss_ce_unscaled: 0.1533 (0.1646)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2171 (0.2443)  loss_giou_unscaled: 0.3885 (0.4302)  cardinality_error_unscaled: 1.0000 (1.2676)\n",
            "Epoch completed in  0:02:21.182733\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [2]  [  0/512]  eta: 0:04:58  lr: 0.000041  class_error: 100.00  loss: 0.9505 (0.9505)  loss_ce: 0.1362 (0.1362)  loss_bbox: 0.5561 (0.5561)  loss_giou: 0.2582 (0.2582)  loss_ce_unscaled: 0.1362 (0.1362)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1112 (0.1112)  loss_giou_unscaled: 0.1291 (0.1291)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.5836  data: 0.2294  max mem: 1968\n",
            "Epoch: [2]  [511/512]  eta: 0:00:00  lr: 0.000041  class_error: 100.00  loss: 1.7535 (1.8070)  loss_ce: 0.1439 (0.1630)  loss_bbox: 0.8229 (0.9360)  loss_giou: 0.6498 (0.7081)  loss_ce_unscaled: 0.1439 (0.1630)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1646 (0.1872)  loss_giou_unscaled: 0.3249 (0.3540)  cardinality_error_unscaled: 1.0000 (1.2725)  time: 0.2538  data: 0.0124  max mem: 1970\n",
            "Epoch: [2] Total time: 0:02:21 (0.2766 s / it)\n",
            "Averaged stats: lr: 0.000041  class_error: 100.00  loss: 1.7535 (1.8070)  loss_ce: 0.1439 (0.1630)  loss_bbox: 0.8229 (0.9360)  loss_giou: 0.6498 (0.7081)  loss_ce_unscaled: 0.1439 (0.1630)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1646 (0.1872)  loss_giou_unscaled: 0.3249 (0.3540)  cardinality_error_unscaled: 1.0000 (1.2725)\n",
            "Epoch completed in  0:02:21.650171\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [3]  [  0/512]  eta: 0:07:34  lr: 0.000036  class_error: 100.00  loss: 1.3850 (1.3850)  loss_ce: 0.2107 (0.2107)  loss_bbox: 0.6314 (0.6314)  loss_giou: 0.5429 (0.5429)  loss_ce_unscaled: 0.2107 (0.2107)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1263 (0.1263)  loss_giou_unscaled: 0.2714 (0.2714)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.8872  data: 0.3590  max mem: 1970\n",
            "Epoch: [3]  [511/512]  eta: 0:00:00  lr: 0.000036  class_error: 100.00  loss: 1.2904 (1.6577)  loss_ce: 0.1327 (0.1637)  loss_bbox: 0.6172 (0.8394)  loss_giou: 0.5500 (0.6545)  loss_ce_unscaled: 0.1327 (0.1637)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1234 (0.1679)  loss_giou_unscaled: 0.2750 (0.3273)  cardinality_error_unscaled: 1.0000 (1.2812)  time: 0.2755  data: 0.0131  max mem: 1970\n",
            "Epoch: [3] Total time: 0:02:24 (0.2820 s / it)\n",
            "Averaged stats: lr: 0.000036  class_error: 100.00  loss: 1.2904 (1.6577)  loss_ce: 0.1327 (0.1637)  loss_bbox: 0.6172 (0.8394)  loss_giou: 0.5500 (0.6545)  loss_ce_unscaled: 0.1327 (0.1637)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1234 (0.1679)  loss_giou_unscaled: 0.2750 (0.3273)  cardinality_error_unscaled: 1.0000 (1.2812)\n",
            "Epoch completed in  0:02:24.398152\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [4]  [  0/512]  eta: 0:04:53  lr: 0.000033  class_error: 100.00  loss: 1.3965 (1.3965)  loss_ce: 0.1549 (0.1549)  loss_bbox: 0.5237 (0.5237)  loss_giou: 0.7178 (0.7178)  loss_ce_unscaled: 0.1549 (0.1549)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1047 (0.1047)  loss_giou_unscaled: 0.3589 (0.3589)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.5737  data: 0.2206  max mem: 1970\n",
            "Epoch: [4]  [511/512]  eta: 0:00:00  lr: 0.000033  class_error: 100.00  loss: 1.2019 (1.5853)  loss_ce: 0.1512 (0.1569)  loss_bbox: 0.6363 (0.7906)  loss_giou: 0.4716 (0.6378)  loss_ce_unscaled: 0.1512 (0.1569)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1273 (0.1581)  loss_giou_unscaled: 0.2358 (0.3189)  cardinality_error_unscaled: 1.0000 (1.2676)  time: 0.2621  data: 0.0110  max mem: 1970\n",
            "Epoch: [4] Total time: 0:02:28 (0.2903 s / it)\n",
            "Averaged stats: lr: 0.000033  class_error: 100.00  loss: 1.2019 (1.5853)  loss_ce: 0.1512 (0.1569)  loss_bbox: 0.6363 (0.7906)  loss_giou: 0.4716 (0.6378)  loss_ce_unscaled: 0.1512 (0.1569)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1273 (0.1581)  loss_giou_unscaled: 0.2358 (0.3189)  cardinality_error_unscaled: 1.0000 (1.2676)\n",
            "Epoch completed in  0:02:28.630685\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [5]  [  0/512]  eta: 0:04:55  lr: 0.000030  class_error: 100.00  loss: 0.8223 (0.8223)  loss_ce: 0.1988 (0.1988)  loss_bbox: 0.2697 (0.2697)  loss_giou: 0.3538 (0.3538)  loss_ce_unscaled: 0.1988 (0.1988)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0539 (0.0539)  loss_giou_unscaled: 0.1769 (0.1769)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.5779  data: 0.2278  max mem: 1970\n",
            "Epoch: [5]  [511/512]  eta: 0:00:00  lr: 0.000030  class_error: 100.00  loss: 1.2270 (1.4445)  loss_ce: 0.1463 (0.1574)  loss_bbox: 0.6486 (0.7028)  loss_giou: 0.4193 (0.5842)  loss_ce_unscaled: 0.1463 (0.1574)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1297 (0.1406)  loss_giou_unscaled: 0.2096 (0.2921)  cardinality_error_unscaled: 1.0000 (1.2734)  time: 0.3439  data: 0.0138  max mem: 1970\n",
            "Epoch: [5] Total time: 0:02:35 (0.3035 s / it)\n",
            "Averaged stats: lr: 0.000030  class_error: 100.00  loss: 1.2270 (1.4445)  loss_ce: 0.1463 (0.1574)  loss_bbox: 0.6486 (0.7028)  loss_giou: 0.4193 (0.5842)  loss_ce_unscaled: 0.1463 (0.1574)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1297 (0.1406)  loss_giou_unscaled: 0.2096 (0.2921)  cardinality_error_unscaled: 1.0000 (1.2734)\n",
            "Epoch completed in  0:02:35.407445\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [6]  [  0/512]  eta: 0:07:13  lr: 0.000027  class_error: 100.00  loss: 0.9513 (0.9513)  loss_ce: 0.1395 (0.1395)  loss_bbox: 0.5187 (0.5187)  loss_giou: 0.2931 (0.2931)  loss_ce_unscaled: 0.1395 (0.1395)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1037 (0.1037)  loss_giou_unscaled: 0.1466 (0.1466)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.8472  data: 0.4676  max mem: 1970\n",
            "Epoch: [6]  [511/512]  eta: 0:00:00  lr: 0.000027  class_error: 100.00  loss: 1.5697 (1.3841)  loss_ce: 0.1374 (0.1604)  loss_bbox: 0.7068 (0.6613)  loss_giou: 0.7084 (0.5624)  loss_ce_unscaled: 0.1374 (0.1604)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1414 (0.1323)  loss_giou_unscaled: 0.3542 (0.2812)  cardinality_error_unscaled: 1.0000 (1.2764)  time: 0.2756  data: 0.0109  max mem: 1972\n",
            "Epoch: [6] Total time: 0:02:40 (0.3135 s / it)\n",
            "Averaged stats: lr: 0.000027  class_error: 100.00  loss: 1.5697 (1.3841)  loss_ce: 0.1374 (0.1604)  loss_bbox: 0.7068 (0.6613)  loss_giou: 0.7084 (0.5624)  loss_ce_unscaled: 0.1374 (0.1604)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1414 (0.1323)  loss_giou_unscaled: 0.3542 (0.2812)  cardinality_error_unscaled: 1.0000 (1.2764)\n",
            "Epoch completed in  0:02:40.501194\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [7]  [  0/512]  eta: 0:05:23  lr: 0.000024  class_error: 100.00  loss: 1.8938 (1.8938)  loss_ce: 0.2126 (0.2126)  loss_bbox: 0.6116 (0.6116)  loss_giou: 1.0696 (1.0696)  loss_ce_unscaled: 0.2126 (0.2126)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1223 (0.1223)  loss_giou_unscaled: 0.5348 (0.5348)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.6327  data: 0.2352  max mem: 1972\n",
            "Epoch: [7]  [511/512]  eta: 0:00:00  lr: 0.000024  class_error: 100.00  loss: 1.1234 (1.3386)  loss_ce: 0.1586 (0.1576)  loss_bbox: 0.4507 (0.6319)  loss_giou: 0.4791 (0.5491)  loss_ce_unscaled: 0.1586 (0.1576)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0901 (0.1264)  loss_giou_unscaled: 0.2395 (0.2746)  cardinality_error_unscaled: 1.0000 (1.2725)  time: 0.3575  data: 0.0130  max mem: 1973\n",
            "Epoch: [7] Total time: 0:02:43 (0.3195 s / it)\n",
            "Averaged stats: lr: 0.000024  class_error: 100.00  loss: 1.1234 (1.3386)  loss_ce: 0.1586 (0.1576)  loss_bbox: 0.4507 (0.6319)  loss_giou: 0.4791 (0.5491)  loss_ce_unscaled: 0.1586 (0.1576)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0901 (0.1264)  loss_giou_unscaled: 0.2395 (0.2746)  cardinality_error_unscaled: 1.0000 (1.2725)\n",
            "Epoch completed in  0:02:43.606031\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [8]  [  0/512]  eta: 0:05:16  lr: 0.000022  class_error: 100.00  loss: 1.1200 (1.1200)  loss_ce: 0.2294 (0.2294)  loss_bbox: 0.4739 (0.4739)  loss_giou: 0.4167 (0.4167)  loss_ce_unscaled: 0.2294 (0.2294)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0948 (0.0948)  loss_giou_unscaled: 0.2084 (0.2084)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.6182  data: 0.2354  max mem: 1973\n",
            "Epoch: [8]  [511/512]  eta: 0:00:00  lr: 0.000022  class_error: 100.00  loss: 1.1828 (1.2683)  loss_ce: 0.1412 (0.1568)  loss_bbox: 0.5106 (0.5966)  loss_giou: 0.5085 (0.5149)  loss_ce_unscaled: 0.1412 (0.1568)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1021 (0.1193)  loss_giou_unscaled: 0.2542 (0.2574)  cardinality_error_unscaled: 1.0000 (1.2744)  time: 0.3408  data: 0.0121  max mem: 1973\n",
            "Epoch: [8] Total time: 0:02:48 (0.3283 s / it)\n",
            "Averaged stats: lr: 0.000022  class_error: 100.00  loss: 1.1828 (1.2683)  loss_ce: 0.1412 (0.1568)  loss_bbox: 0.5106 (0.5966)  loss_giou: 0.5085 (0.5149)  loss_ce_unscaled: 0.1412 (0.1568)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1021 (0.1193)  loss_giou_unscaled: 0.2542 (0.2574)  cardinality_error_unscaled: 1.0000 (1.2744)\n",
            "Epoch completed in  0:02:48.098808\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [9]  [  0/512]  eta: 0:05:33  lr: 0.000019  class_error: 100.00  loss: 0.8303 (0.8303)  loss_ce: 0.1060 (0.1060)  loss_bbox: 0.3696 (0.3696)  loss_giou: 0.3547 (0.3547)  loss_ce_unscaled: 0.1060 (0.1060)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0739 (0.0739)  loss_giou_unscaled: 0.1774 (0.1774)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.6516  data: 0.2383  max mem: 1973\n",
            "Epoch: [9]  [511/512]  eta: 0:00:00  lr: 0.000019  class_error: 100.00  loss: 0.9504 (1.1985)  loss_ce: 0.1497 (0.1569)  loss_bbox: 0.4316 (0.5463)  loss_giou: 0.4049 (0.4952)  loss_ce_unscaled: 0.1497 (0.1569)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0863 (0.1093)  loss_giou_unscaled: 0.2025 (0.2476)  cardinality_error_unscaled: 1.0000 (1.2734)  time: 0.3718  data: 0.0132  max mem: 1973\n",
            "Epoch: [9] Total time: 0:02:52 (0.3371 s / it)\n",
            "Averaged stats: lr: 0.000019  class_error: 100.00  loss: 0.9504 (1.1985)  loss_ce: 0.1497 (0.1569)  loss_bbox: 0.4316 (0.5463)  loss_giou: 0.4049 (0.4952)  loss_ce_unscaled: 0.1497 (0.1569)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0863 (0.1093)  loss_giou_unscaled: 0.2025 (0.2476)  cardinality_error_unscaled: 1.0000 (1.2734)\n",
            "Epoch completed in  0:02:52.598093\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [10]  [  0/512]  eta: 0:05:19  lr: 0.000017  class_error: 100.00  loss: 1.5004 (1.5004)  loss_ce: 0.1252 (0.1252)  loss_bbox: 0.7187 (0.7187)  loss_giou: 0.6565 (0.6565)  loss_ce_unscaled: 0.1252 (0.1252)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1437 (0.1437)  loss_giou_unscaled: 0.3282 (0.3282)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.6244  data: 0.2365  max mem: 1973\n",
            "Epoch: [10]  [511/512]  eta: 0:00:00  lr: 0.000017  class_error: 100.00  loss: 1.0591 (1.2276)  loss_ce: 0.1347 (0.1552)  loss_bbox: 0.5024 (0.5554)  loss_giou: 0.4634 (0.5171)  loss_ce_unscaled: 0.1347 (0.1552)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1005 (0.1111)  loss_giou_unscaled: 0.2317 (0.2585)  cardinality_error_unscaled: 1.0000 (1.2764)  time: 0.2917  data: 0.0116  max mem: 1973\n",
            "Epoch: [10] Total time: 0:02:53 (0.3392 s / it)\n",
            "Averaged stats: lr: 0.000017  class_error: 100.00  loss: 1.0591 (1.2276)  loss_ce: 0.1347 (0.1552)  loss_bbox: 0.5024 (0.5554)  loss_giou: 0.4634 (0.5171)  loss_ce_unscaled: 0.1347 (0.1552)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1005 (0.1111)  loss_giou_unscaled: 0.2317 (0.2585)  cardinality_error_unscaled: 1.0000 (1.2764)\n",
            "Epoch completed in  0:02:53.671662\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [11]  [  0/512]  eta: 0:05:35  lr: 0.000016  class_error: 100.00  loss: 1.2261 (1.2261)  loss_ce: 0.1499 (0.1499)  loss_bbox: 0.3441 (0.3441)  loss_giou: 0.7321 (0.7321)  loss_ce_unscaled: 0.1499 (0.1499)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0688 (0.0688)  loss_giou_unscaled: 0.3660 (0.3660)  cardinality_error_unscaled: 1.5000 (1.5000)  time: 0.6555  data: 0.2534  max mem: 1973\n",
            "Epoch: [11]  [511/512]  eta: 0:00:00  lr: 0.000016  class_error: 100.00  loss: 1.0086 (1.1880)  loss_ce: 0.1585 (0.1584)  loss_bbox: 0.4648 (0.5324)  loss_giou: 0.3912 (0.4972)  loss_ce_unscaled: 0.1585 (0.1584)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0930 (0.1065)  loss_giou_unscaled: 0.1956 (0.2486)  cardinality_error_unscaled: 1.5000 (1.2754)  time: 0.3807  data: 0.0143  max mem: 1973\n",
            "Epoch: [11] Total time: 0:02:59 (0.3505 s / it)\n",
            "Averaged stats: lr: 0.000016  class_error: 100.00  loss: 1.0086 (1.1880)  loss_ce: 0.1585 (0.1584)  loss_bbox: 0.4648 (0.5324)  loss_giou: 0.3912 (0.4972)  loss_ce_unscaled: 0.1585 (0.1584)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0930 (0.1065)  loss_giou_unscaled: 0.1956 (0.2486)  cardinality_error_unscaled: 1.5000 (1.2754)\n",
            "Epoch completed in  0:02:59.466026\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [12]  [  0/512]  eta: 0:05:52  lr: 0.000014  class_error: 100.00  loss: 1.1951 (1.1951)  loss_ce: 0.1577 (0.1577)  loss_bbox: 0.4399 (0.4399)  loss_giou: 0.5975 (0.5975)  loss_ce_unscaled: 0.1577 (0.1577)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0880 (0.0880)  loss_giou_unscaled: 0.2987 (0.2987)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.6879  data: 0.2422  max mem: 1973\n",
            "Epoch: [12]  [511/512]  eta: 0:00:00  lr: 0.000014  class_error: 100.00  loss: 1.2150 (1.1386)  loss_ce: 0.1372 (0.1587)  loss_bbox: 0.5150 (0.5053)  loss_giou: 0.5310 (0.4746)  loss_ce_unscaled: 0.1372 (0.1587)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1030 (0.1011)  loss_giou_unscaled: 0.2655 (0.2373)  cardinality_error_unscaled: 1.0000 (1.2744)  time: 0.3458  data: 0.0119  max mem: 1973\n",
            "Epoch: [12] Total time: 0:02:57 (0.3466 s / it)\n",
            "Averaged stats: lr: 0.000014  class_error: 100.00  loss: 1.2150 (1.1386)  loss_ce: 0.1372 (0.1587)  loss_bbox: 0.5150 (0.5053)  loss_giou: 0.5310 (0.4746)  loss_ce_unscaled: 0.1372 (0.1587)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1030 (0.1011)  loss_giou_unscaled: 0.2655 (0.2373)  cardinality_error_unscaled: 1.0000 (1.2744)\n",
            "Epoch completed in  0:02:57.447826\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [13]  [  0/512]  eta: 0:05:43  lr: 0.000013  class_error: 100.00  loss: 1.1455 (1.1455)  loss_ce: 0.1358 (0.1358)  loss_bbox: 0.5701 (0.5701)  loss_giou: 0.4396 (0.4396)  loss_ce_unscaled: 0.1358 (0.1358)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.1140 (0.1140)  loss_giou_unscaled: 0.2198 (0.2198)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.6714  data: 0.2402  max mem: 1973\n",
            "Epoch: [13]  [511/512]  eta: 0:00:00  lr: 0.000013  class_error: 100.00  loss: 1.1321 (1.1256)  loss_ce: 0.1391 (0.1565)  loss_bbox: 0.4684 (0.5024)  loss_giou: 0.4888 (0.4667)  loss_ce_unscaled: 0.1391 (0.1565)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0937 (0.1005)  loss_giou_unscaled: 0.2444 (0.2333)  cardinality_error_unscaled: 1.0000 (1.2686)  time: 0.3128  data: 0.0116  max mem: 1973\n",
            "Epoch: [13] Total time: 0:02:54 (0.3417 s / it)\n",
            "Averaged stats: lr: 0.000013  class_error: 100.00  loss: 1.1321 (1.1256)  loss_ce: 0.1391 (0.1565)  loss_bbox: 0.4684 (0.5024)  loss_giou: 0.4888 (0.4667)  loss_ce_unscaled: 0.1391 (0.1565)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.0937 (0.1005)  loss_giou_unscaled: 0.2444 (0.2333)  cardinality_error_unscaled: 1.0000 (1.2686)\n",
            "Epoch completed in  0:02:54.947850\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Epoch: [14]  [  0/512]  eta: 0:05:29  lr: 0.000011  class_error: 100.00  loss: 1.6759 (1.6759)  loss_ce: 0.1226 (0.1226)  loss_bbox: 1.0094 (1.0094)  loss_giou: 0.5439 (0.5439)  loss_ce_unscaled: 0.1226 (0.1226)  class_error_unscaled: 100.0000 (100.0000)  loss_bbox_unscaled: 0.2019 (0.2019)  loss_giou_unscaled: 0.2719 (0.2719)  cardinality_error_unscaled: 1.0000 (1.0000)  time: 0.6436  data: 0.2433  max mem: 1973\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0db344ce8f71>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-77c7fdf41df8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, criterion, postprocessors, device)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mepoch_timing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         train_stats = train_one_epoch(\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/table-transformer/detr/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, data_loader, optimizer, device, epoch, max_norm, max_batches_per_epoch, print_freq)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mweight_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/table-transformer/detr/models/detr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Retrieve the matching between the outputs of the last layer and the targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_without_aux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Compute the average number of target boxes accross all nodes, for normalization purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/table-transformer/detr/models/matcher.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Compute the L1 cost between boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mcost_bbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Compute the giou cost betwen boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist_if_necessary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cdist only supports at least 2D tensors, X2 got: 1D"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Đường dẫn tới file JSON bạn muốn ghi\n",
        "json_file_path = '/content/manual_args.json'\n",
        "\n",
        "# Ghi thông tin từ manual_args_dict vào file JSON\n",
        "with open(json_file_path, 'w') as json_file:\n",
        "    json.dump(manual_args_dict, json_file, indent=4)\n",
        "\n",
        "print(f'The configuration has been saved to {json_file_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpB-7CrM7CZF",
        "outputId": "c6c81c38-7dba-4b67-c03b-9fb01707cb76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The configuration has been saved to /content/manual_args.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HoanChan/TableVision.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUDsEO1N6uM3",
        "outputId": "a1fe84f8-10fd-4460-ba35-32a513450795"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TableVision'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 134 (delta 12), reused 46 (delta 6), pack-reused 81\u001b[K\n",
            "Receiving objects: 100% (134/134), 209.71 MiB | 36.92 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Updating files: 100% (71/71), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pth_file(input_file, output_file1, output_file2):\n",
        "    with open(input_file, 'rb') as f:\n",
        "        data = f.read()\n",
        "\n",
        "    half_len = len(data) // 2\n",
        "\n",
        "    with open(output_file1, 'wb') as f1, open(output_file2, 'wb') as f2:\n",
        "        f1.write(data[:half_len])\n",
        "        f2.write(data[half_len:])\n",
        "\n",
        "def combine_pth_files(input_file1, input_file2, output_file):\n",
        "    with open(input_file1, 'rb') as f1, open(input_file2, 'rb') as f2:\n",
        "        data1 = f1.read()\n",
        "        data2 = f2.read()\n",
        "\n",
        "    combined_data = data1 + data2\n",
        "\n",
        "    with open(output_file, 'wb') as f:\n",
        "        f.write(combined_data)\n",
        "\n",
        "combine_pth_files(\"/content/TableVision/models/pubtables1m_detection_detr_r18.pth_part1\", \"/content/TableVision/models/pubtables1m_detection_detr_r18.pth_part2\", \"/content/TableVision/models/pubtables1m_detection_detr_r18.pth\")\n",
        "combine_pth_files(\"/content/TableVision/models/pubtables1m_structure_detr_r18.pth_part1\", \"/content/TableVision/models/pubtables1m_structure_detr_r18.pth_part2\", \"/content/TableVision/models/pubtables1m_structure_detr_r18.pth\")\n"
      ],
      "metadata": {
        "id": "ZI5a-QhO7NfS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before clearing sys.path:\")\n",
        "print(sys.path)\n",
        "# print(sys.path.index('/root/.ipython'))\n",
        "sys.path=sys.path[:10]\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrckPio4_qvs",
        "outputId": "002ad5ed-8e38-47c5-8af3-d316d11e4503"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before clearing sys.path:\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/content/TableVision/', '/content/table-transformer/']\n",
            "['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/content/TableVision/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# Thêm đường dẫn đến thư mục 'src' vào danh sách đường dẫn\n",
        "sys.path=sys.path[:10]\n",
        "\n",
        "# sys.path.append('/content/TableVision/')\n",
        "sys.path.append('/content/table-transformer/')\n",
        "# sys.path.append('/content/table-transformer/src/')\n",
        "# sys.path.append('/content/table-transformer/detr/')\n",
        "\n",
        "from src.inference import TableExtractionPipeline\n",
        "\n",
        "# Create inference pipeline\n",
        "pipe = TableExtractionPipeline(det_config_path='/content/manual_args.json',\n",
        "                               det_model_path='/content/models/model_13.pth', det_device='cuda',\n",
        "                               str_config_path='/content/table-transformer/src/structure_config.json',\n",
        "                               str_model_path='/content/TableVision/models/pubtables1m_structure_detr_r18.pth', str_device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "eIdrFGo060w_",
        "outputId": "1f098306-8b39-4368-c50e-6951f041afac"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-dd1037d14762>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# sys.path.append('/content/table-transformer/detr/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTableExtractionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create inference pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TableVision/src/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../detr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_model' from 'main' (/content/table-transformer/detr/main.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from src.inference import visualize_detected_tables, visualize_cells\n",
        "\n",
        "def detectTable(pipe, img_path):\n",
        "  img = Image.open(img_path)\n",
        "  tokens = {}\n",
        "  extracted_tables = pipe.recognize(img, tokens, out_objects=True, out_cells=True, out_html=True, out_csv=True)\n",
        "\n",
        "  # Select table (there could be more than one)\n",
        "  try:\n",
        "    extracted_table = extracted_tables[0]\n",
        "  except:\n",
        "    extracted_table = extracted_tables\n",
        "\n",
        "  # Get output in desired format\n",
        "  objects = extracted_table['objects']\n",
        "  cells = extracted_table['cells']\n",
        "  csv = extracted_table['csv']\n",
        "  html = extracted_table['html']\n",
        "\n",
        "  visualize_detected_tables(img, objects, \"/content/1.jpg\")\n",
        "  visualize_cells(img, cells[0], \"/content/2.jpg\")\n",
        "\n",
        "  img0 = Image.open(img_path)\n",
        "  img1 = Image.open('/content/1.jpg')\n",
        "  img2 = Image.open('/content/2.jpg')\n",
        "\n",
        "  plt.figure(figsize=(15, 5))\n",
        "\n",
        "  plt.subplot(131)\n",
        "  plt.imshow(img0)\n",
        "  plt.title('Image 0')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplot(132)\n",
        "  plt.imshow(img1)\n",
        "  plt.title('Image 1')\n",
        "  plt.axis('off')\n",
        "\n",
        "\n",
        "  plt.subplot(133)\n",
        "  plt.imshow(img2)\n",
        "  plt.title('Image 2')\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "Ta1EEjLZ8tid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detectTable(pipe, \"/content/TableVision/sample/vn0.jpg\")"
      ],
      "metadata": {
        "id": "lIJGdIGL8vMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}