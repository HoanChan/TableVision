{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/HoanChan/TNCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy danh sách các file xml trong thư mục TNCR\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#lấy danh sách các file xml trong thư mục TNCR\n",
    "files = glob.glob('TNCR/*.xml')\n",
    "\n",
    "#in ra số lượng file\n",
    "print(len(files))\n",
    "\n",
    "#in ra 10 cái\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in nội dụng 1 file\n",
    "\n",
    "with open(files[0], 'r', encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "class Anotation:\n",
    "  def __init__(self, path, folder, objects, size):\n",
    "      self.path = path\n",
    "      self.folder = folder\n",
    "      self.objects = objects\n",
    "      self.size = size\n",
    "\n",
    "class PVOC:\n",
    "    def __init__(self, name, pose, truncated, difficult, bbox):        \n",
    "        self.name = name\n",
    "        self.pose = pose\n",
    "        self.truncated = truncated\n",
    "        self.difficult = difficult\n",
    "        self.bndbox = bbox        \n",
    "\n",
    "def read_xml_files(folder_path):\n",
    "\n",
    "    # Kiểm tra xem đường dẫn thư mục tồn tại hay không\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Thư mục '{folder_path}' không tồn tại.\")\n",
    "        return []\n",
    "\n",
    "    # Lấy danh sách các file XML trong thư mục\n",
    "    xml_files = glob.glob(folder_path + '*.xml')\n",
    "\n",
    "    anos = []  # Danh sách các đối tượng từ các file XML\n",
    "\n",
    "    # Đọc nội dung của từng file XML và chuyển đổi thành đối tượng\n",
    "    for xml_file in xml_files:\n",
    "\n",
    "        # Đọc nội dung file XML và tạo cây phân tích cú pháp\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        path = \"/content/TNCR/\" + root.find('filename').text\n",
    "        folder = root.find('folder').text\n",
    "        width = int(root.find('size/width').text)\n",
    "        height = int(root.find('size/height').text)\n",
    "        depth = int(root.find('size/depth').text)\n",
    "\n",
    "        size = [width, height, depth]\n",
    "\n",
    "        objects=[]\n",
    "\n",
    "        for object_ in root.iter('object'):\n",
    "          \n",
    "          name = object_.find('name').text\n",
    "          pose = object_.find('pose').text\n",
    "          truncated = object_.find('truncated').text\n",
    "          difficult = object_.find('difficult').text\n",
    "\n",
    "          ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "          for box in object_.findall(\"bndbox\"):\n",
    "              ymin = float(box.find(\"ymin\").text)\n",
    "              xmin = float(box.find(\"xmin\").text)\n",
    "              ymax = float(box.find(\"ymax\").text)\n",
    "              xmax = float(box.find(\"xmax\").text)\n",
    "\n",
    "          bbox = [xmin, ymin, xmax, ymax] # PASCAL VOC   \n",
    "\n",
    "          obj = PVOC(name = name, pose = pose, truncated = truncated, difficult = difficult, bbox = bbox)\n",
    "          objects.append(obj)\n",
    "\n",
    "        ano = Anotation(path = path, folder = folder, objects = objects, size = size)\n",
    "        anos.append(ano)\n",
    "\n",
    "    return anos\n",
    "\n",
    "\n",
    "# Thay đổi folder_path thành đường dẫn thư mục chứa các file XML\n",
    "folder_path = \"/content/TNCR/\"\n",
    "anos = read_xml_files(folder_path)\n",
    "\n",
    "# In thông tin các đối tượng\n",
    "ano = anos[5]\n",
    "print(\"Path:\", ano.path)\n",
    "print(\"Folder:\", ano.folder)\n",
    "print(\"Size:\", ano.size)\n",
    "print(\"bbox:\")\n",
    "for obj in ano.objects:\n",
    "  print(\"  Name:\", obj.name)\n",
    "  print(\"  Pose:\", obj.pose)\n",
    "  print(\"  Truncated:\", obj.truncated)\n",
    "  print(\"  Difficult:\", obj.difficult)\n",
    "  print(\"  Bounding Box:\", obj.bndbox )\n",
    "  print(\"  -----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_bounding_boxes(images, indices):\n",
    "    num_images = len(indices)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(5*3/4*num_images, 5))\n",
    "\n",
    "    for i, index in enumerate(indices):\n",
    "        ano = images[index - 1]\n",
    "        image_path = ano.path\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        for obj in ano.objects:\n",
    "          # Lấy thông tin bounding box\n",
    "          xmin = obj.bndbox[0]\n",
    "          ymin = obj.bndbox[1]\n",
    "          xmax = obj.bndbox[2]\n",
    "          ymax = obj.bndbox[3]\n",
    "\n",
    "          # Vẽ bounding box lên ảnh\n",
    "          cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "\n",
    "          # Vẽ nhãn lên ảnh\n",
    "          label = obj.name + ' - ' + obj.pose\n",
    "          cv2.putText(image, label, (int(xmin), int(ymin)-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "\n",
    "        # Hiển thị ảnh với bounding box trên subplot tương ứng\n",
    "        axes[i].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(ano.folder)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices_to_draw = random.choices(range(len(anos)), k= 4)\n",
    "print(indices_to_draw)\n",
    "draw_bounding_boxes(anos, indices_to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label = []\n",
    "for a in anos:\n",
    "  label = [o.name for o in a.objects]\n",
    "  for p in label:\n",
    "    if(not p in list_label):\n",
    "      list_label.append(p)\n",
    "\n",
    "print(list_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations, transform=None):\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        annotation = self.annotations[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(annotation.path)\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert bounding box coordinates to tensor\n",
    "        bboxes = torch.tensor(annotation.objects[0].bndbox)\n",
    "\n",
    "        return image, bboxes\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_annos, test_annos = train_test_split(anos, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = CustomDataset(train_annos, transform=transform)\n",
    "test_dataset = CustomDataset(test_annos, transform=transform)\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 4)  # 4 for bounding box coordinates (xmin, ymin, xmax, ymax)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, bboxes in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        images = images.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, bboxes)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print epoch loss\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, bboxes in tqdm(test_loader, desc=\"Evaluation\"):\n",
    "        images = images.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, bboxes)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Print evaluation loss\n",
    "    evaluation_loss = total_loss / len(test_loader)\n",
    "    print(f\"Evaluation Loss: {evaluation_loss}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
